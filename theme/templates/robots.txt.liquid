# we use Shopify as our ecommerce platform
{%- comment -%}
# Caution! Please read https://help.shopify.com/en/manual/promoting-marketing/seo/editing-robots-txt
{% endcomment %}
{% for group in robots.default_groups %}
  {{- group.user_agent -}}

  {% for rule in group.rules %}
    {{- rule -}}
  {% endfor %}

  {%- comment -%}
    NOTE: What this code says is; if the user_agent (Robots name) is equal to *,
          which applies to all robots, then disallow the following:

          1.  /apps            – This will block apps that use a proxy url(*)
          2.  /blogs/*/tagged  – This will block blog tags being crawled
          3.  /collections/*/* – This will block product tags being crawled(**)
          4.  /*?q=            – This will block the default vendors and types collection pages being crawled

          Beware:
          (*)  This is the default but exact proxy URLs can be customized
          (**) Be careful with this, it may prevent products being crawled, if you don’t customise internal links
                i.e. remove `within: collection` liquid filter from PLPs etc.

  {%- endcomment -%}

  {%- if group.user_agent.value == '*' -%}
    {{- 'Disallow: /apps*' }}
    {{- 'Disallow: /collections/all*' }}
    {{- 'Disallow: /*?q=*' }}
    {{- 'Disallow: /collections/*/*' }}
    {{- 'Disallow: /blogs/*/tagged/*' }}
  {%- endif -%}

  {%- if group.sitemap != blank -%}
    {{ group.sitemap }}
  {%- endif -%}
{% endfor %}